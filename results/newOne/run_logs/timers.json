{
    "name": "root",
    "gauges": {
        "MoveBehavior.Policy.Entropy.mean": {
            "value": 2.435127019882202,
            "min": 2.434392213821411,
            "max": 2.718111276626587,
            "count": 54
        },
        "MoveBehavior.Policy.Entropy.sum": {
            "value": 1217446.625,
            "min": 1217079.25,
            "max": 1360403.875,
            "count": 54
        },
        "MoveBehavior.Step.mean": {
            "value": 26999941.0,
            "min": 499936.0,
            "max": 26999941.0,
            "count": 54
        },
        "MoveBehavior.Step.sum": {
            "value": 26999941.0,
            "min": 499936.0,
            "max": 26999941.0,
            "count": 54
        },
        "MoveBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 2673.3544921875,
            "min": 1641.730712890625,
            "max": 2676.3740234375,
            "count": 54
        },
        "MoveBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 21389510.0,
            "min": 13181456.0,
            "max": 21421698.0,
            "count": 54
        },
        "MoveBehavior.Losses.PolicyLoss.mean": {
            "value": 0.022486674610263435,
            "min": 0.02247387278895528,
            "max": 0.024708644636482206,
            "count": 54
        },
        "MoveBehavior.Losses.PolicyLoss.sum": {
            "value": 1.0793603812926449,
            "min": 1.0793603812926449,
            "max": 1.210723587187628,
            "count": 54
        },
        "MoveBehavior.Losses.ValueLoss.mean": {
            "value": 1612.2465031094023,
            "min": 1088.5678653223983,
            "max": 9478.382709701615,
            "count": 54
        },
        "MoveBehavior.Losses.ValueLoss.sum": {
            "value": 77387.8321492513,
            "min": 53339.82540079752,
            "max": 454962.3700656775,
            "count": 54
        },
        "MoveBehavior.Policy.LearningRate.mean": {
            "value": 0.00029839494850251736,
            "min": 0.00029839494850251736,
            "max": 0.0002999846810226063,
            "count": 54
        },
        "MoveBehavior.Policy.LearningRate.sum": {
            "value": 0.014322957528120833,
            "min": 0.014322957528120833,
            "max": 0.014696332917622358,
            "count": 54
        },
        "MoveBehavior.Policy.Epsilon.mean": {
            "value": 0.19946498265583334,
            "min": 0.19946498265583334,
            "max": 0.1999948936725,
            "count": 54
        },
        "MoveBehavior.Policy.Epsilon.sum": {
            "value": 9.57431916748,
            "min": 9.57431916748,
            "max": 9.798777638799999,
            "count": 54
        },
        "MoveBehavior.Policy.Beta.mean": {
            "value": 0.004973302634526083,
            "min": 0.004973302634526083,
            "max": 0.004999745194257751,
            "count": 54
        },
        "MoveBehavior.Policy.Beta.sum": {
            "value": 0.238718526457252,
            "min": 0.238718526457252,
            "max": 0.24493900417612002,
            "count": 54
        },
        "MoveBehavior.Environment.EpisodeLength.mean": {
            "value": 992.3320079522863,
            "min": 901.4817518248175,
            "max": 997.48,
            "count": 54
        },
        "MoveBehavior.Environment.EpisodeLength.sum": {
            "value": 499143.0,
            "min": 494012.0,
            "max": 507025.0,
            "count": 54
        },
        "MoveBehavior.Environment.CumulativeReward.mean": {
            "value": 26101.251910048497,
            "min": 18662.07160836937,
            "max": 26145.331947890107,
            "count": 54
        },
        "MoveBehavior.Environment.CumulativeReward.sum": {
            "value": 13128929.710754395,
            "min": 10226815.241386414,
            "max": 13235550.758377075,
            "count": 54
        },
        "MoveBehavior.Policy.ExtrinsicReward.mean": {
            "value": 26101.251910048497,
            "min": 18662.07160836937,
            "max": 26145.331947890107,
            "count": 54
        },
        "MoveBehavior.Policy.ExtrinsicReward.sum": {
            "value": 13128929.710754395,
            "min": 10226815.241386414,
            "max": 13235550.758377075,
            "count": 54
        },
        "MoveBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "MoveBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 54
        },
        "WarBehavior.Policy.Entropy.mean": {
            "value": 0.4791586697101593,
            "min": 0.4791586697101593,
            "max": 0.5776760578155518,
            "count": 3
        },
        "WarBehavior.Policy.Entropy.sum": {
            "value": 239564.484375,
            "min": 239564.484375,
            "max": 288867.5,
            "count": 3
        },
        "WarBehavior.Environment.EpisodeLength.mean": {
            "value": 36.25750689218389,
            "min": 36.25750689218389,
            "max": 45.54939018713341,
            "count": 3
        },
        "WarBehavior.Environment.EpisodeLength.sum": {
            "value": 486612.0,
            "min": 486612.0,
            "max": 489246.0,
            "count": 3
        },
        "WarBehavior.Step.mean": {
            "value": 1499994.0,
            "min": 499987.0,
            "max": 1499994.0,
            "count": 3
        },
        "WarBehavior.Step.sum": {
            "value": 1499994.0,
            "min": 499987.0,
            "max": 1499994.0,
            "count": 3
        },
        "WarBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.09075824171304703,
            "min": -0.09075824171304703,
            "max": 0.03142296150326729,
            "count": 3
        },
        "WarBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": -1426.901123046875,
            "min": -1426.901123046875,
            "max": 469.2705078125,
            "count": 3
        },
        "WarBehavior.Environment.CumulativeReward.mean": {
            "value": -0.08047690014903129,
            "min": -0.08047690014903129,
            "max": 0.18340936598082117,
            "count": 3
        },
        "WarBehavior.Environment.CumulativeReward.sum": {
            "value": -1080.0,
            "min": -1080.0,
            "max": 1970.0,
            "count": 3
        },
        "WarBehavior.Policy.ExtrinsicReward.mean": {
            "value": -0.08047690014903129,
            "min": -0.08047690014903129,
            "max": 0.18340936598082117,
            "count": 3
        },
        "WarBehavior.Policy.ExtrinsicReward.sum": {
            "value": -1080.0,
            "min": -1080.0,
            "max": 1970.0,
            "count": 3
        },
        "WarBehavior.Losses.PolicyLoss.mean": {
            "value": 0.024277002290984125,
            "min": 0.022286464437739694,
            "max": 0.024277002290984125,
            "count": 3
        },
        "WarBehavior.Losses.PolicyLoss.sum": {
            "value": 1.189573112258222,
            "min": 1.0697502930115053,
            "max": 1.189573112258222,
            "count": 3
        },
        "WarBehavior.Losses.ValueLoss.mean": {
            "value": 18.864306457026476,
            "min": 15.05588810675674,
            "max": 18.864306457026476,
            "count": 3
        },
        "WarBehavior.Losses.ValueLoss.sum": {
            "value": 924.3510163942973,
            "min": 722.6826291243235,
            "max": 924.3510163942973,
            "count": 3
        },
        "WarBehavior.Policy.LearningRate.mean": {
            "value": 0.0002999248587593328,
            "min": 0.0002999248587593328,
            "max": 0.0002999849057450314,
            "count": 3
        },
        "WarBehavior.Policy.LearningRate.sum": {
            "value": 0.014696318079207307,
            "min": 0.014399275475761506,
            "max": 0.014697796714454425,
            "count": 3
        },
        "WarBehavior.Policy.Epsilon.mean": {
            "value": 0.19997495291142858,
            "min": 0.19997495291142858,
            "max": 0.19999496858,
            "count": 3
        },
        "WarBehavior.Policy.Epsilon.sum": {
            "value": 9.79877269266,
            "min": 9.59975849184,
            "max": 9.799265571240001,
            "count": 3
        },
        "WarBehavior.Policy.Beta.mean": {
            "value": 0.004998750150280286,
            "min": 0.004998750150280286,
            "max": 0.004999748932142,
            "count": 3
        },
        "WarBehavior.Policy.Beta.sum": {
            "value": 0.24493875736373402,
            "min": 0.239987948742816,
            "max": 0.244963352004876,
            "count": 3
        },
        "WarBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        },
        "WarBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 3
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1707015036",
        "python_version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Val\\UnityProjects\\MagisterkaEnv\\venv\\Scripts\\mlagents-learn --run-id newOne --force configuration.yaml",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1707033338"
    },
    "total": 18302.310624499998,
    "count": 1,
    "self": 0.0033994999976130202,
    "children": {
        "run_training.setup": {
            "total": 0.04376710000000006,
            "count": 1,
            "self": 0.04376710000000006
        },
        "TrainerController.start_learning": {
            "total": 18302.2634579,
            "count": 1,
            "self": 19.249968200754665,
            "children": {
                "TrainerController._reset_env": {
                    "total": 2.5216078,
                    "count": 1,
                    "self": 2.5216078
                },
                "TrainerController.advance": {
                    "total": 18280.380434099243,
                    "count": 1765505,
                    "self": 24.456499099251232,
                    "children": {
                        "env_step": {
                            "total": 12097.248339900238,
                            "count": 1765505,
                            "self": 9735.79401850036,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 2349.4215517999346,
                                    "count": 1765505,
                                    "self": 90.18175680140757,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 2259.239794998527,
                                            "count": 3394644,
                                            "self": 363.4687135975598,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 1895.7710814009672,
                                                    "count": 3394644,
                                                    "self": 1895.7710814009672
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 12.032769599941771,
                                    "count": 1765505,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 18269.506815400615,
                                            "count": 1765505,
                                            "is_parallel": true,
                                            "self": 9913.279921801017,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00042570000000052843,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00018690000000143314,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002387999999990953,
                                                            "count": 6,
                                                            "is_parallel": true,
                                                            "self": 0.0002387999999990953
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 8356.226467899598,
                                                    "count": 1765505,
                                                    "is_parallel": true,
                                                    "self": 165.61863680178703,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 196.1993493991885,
                                                            "count": 1765505,
                                                            "is_parallel": true,
                                                            "self": 196.1993493991885
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 7285.920692198688,
                                                            "count": 1765505,
                                                            "is_parallel": true,
                                                            "self": 7285.920692198688
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 708.4877894999341,
                                                            "count": 3531010,
                                                            "is_parallel": true,
                                                            "self": 263.97746160163723,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 444.5103278982969,
                                                                    "count": 10593030,
                                                                    "is_parallel": true,
                                                                    "self": 444.5103278982969
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 6158.675595099756,
                            "count": 3531009,
                            "self": 56.1244595990629,
                            "children": {
                                "process_trajectory": {
                                    "total": 1288.894473800648,
                                    "count": 3531009,
                                    "self": 1288.5926648006466,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.30180900000141264,
                                            "count": 5,
                                            "self": 0.30180900000141264
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 4813.656661700044,
                                    "count": 2806,
                                    "self": 2059.6156815998847,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 2754.0409801001597,
                                            "count": 84166,
                                            "self": 2754.0409801001597
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.000009307172149e-07,
                    "count": 1,
                    "self": 6.000009307172149e-07
                },
                "TrainerController._save_models": {
                    "total": 0.11144720000083908,
                    "count": 1,
                    "self": 0.01754790000268258,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.0938992999981565,
                            "count": 2,
                            "self": 0.0938992999981565
                        }
                    }
                }
            }
        }
    }
}